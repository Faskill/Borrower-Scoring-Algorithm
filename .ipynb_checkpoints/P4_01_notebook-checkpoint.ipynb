{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc887fa",
   "metadata": {},
   "source": [
    "# Developping a Borrower Scoring Algorithm\n",
    "\n",
    "Last updated : September 25th, 2022\n",
    "\n",
    "## Introduction\n",
    "\n",
    "During this project, I will use a dataset provided by a consumer finance companies to develop a machine learning algorithm that will predict if the borrower will have payment difficulties or not.\n",
    "\n",
    "## 1. Data Loading and Filtering\n",
    "\n",
    "First we will load the necessary packages and dataset and then we will carry on with the Cleaning and Analysis.\n",
    "\n",
    "### 1.1 Loading our packages\n",
    "\n",
    "We will import the necessary packages to run this project: matplotlib, numpy, pandas, seaborn.\n",
    "Since I am running the project on Windows, I will also use sklearnex to increase the speed of sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e59e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "#Importing packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#Setting large figure size for Seaborn\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27),\"font.size\":20,\"axes.titlesize\":20,\"axes.labelsize\":18})\n",
    "\n",
    "#Importing Intel extension for sklearn to improve speed\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e7df6",
   "metadata": {},
   "source": [
    "### 1.2 Loading the dataset\n",
    "\n",
    "We will now load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dede469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app_test = pd.read_csv(\"Data/application_test.csv\", sep=\",\")\n",
    "# app = pd.read_csv(\"Data/application_train.csv\", sep=\",\")\n",
    "\n",
    "# app.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a35290",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "We will now clean our dataset.\n",
    "\n",
    "### 2.1 Cleaning categorical variables\n",
    "\n",
    "We will begin the cleaning process by cleaning categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9354b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing maximum number of info rows \n",
    "pd.options.display.max_info_columns = 130\n",
    "\n",
    "\n",
    "# #Looking at unique valeus of categorical variables\n",
    "# def investigate_categories(df: pd.DataFrame):\n",
    "#     for c in df.columns:\n",
    "#         if df[c].dtype == 'object':\n",
    "#             print(\"Column\",c)\n",
    "#             print(\"Unique values: {}\".format(df[c].unique()))\n",
    "#             print(\"\")\n",
    "#             print(\"-----------------------------------\")\n",
    "            \n",
    "# investigate_categories(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152ac3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Investigating \"XNA\" values in GENDER\n",
    "# app[app[\"CODE_GENDER\"] == 'XNA']\n",
    "# #Only 4 rows\n",
    "\n",
    "# #Let's look at the test data\n",
    "# app_test[app_test[\"CODE_GENDER\"] == 'XNA']\n",
    "# #0 row\n",
    "\n",
    "# #We will replace with the mode\n",
    "# app[\"CODE_GENDER\"] = app[\"CODE_GENDER\"].fillna(app[\"CODE_GENDER\"].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ca7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Investigating \"XNA\" values in ORGANIZATION_TYPE\n",
    "# app[app[\"ORGANIZATION_TYPE\"] == 'XNA']\n",
    "# #55374 rows\n",
    "\n",
    "# app[app[\"ORGANIZATION_TYPE\"] == 'XNA'][\"TARGET\"].value_counts(normalize=True)\n",
    "# #Significant deviation from the normal percentages, so it is interesting to keep these values\n",
    "\n",
    "# #They will be encoded during the feature engineering part of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec0994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Looking at \"nan\" values in EMERGENCYSTATE_MODE\n",
    "# print(len(app[app[\"EMERGENCYSTATE_MODE\"].isna()]))\n",
    "\n",
    "# app[app[\"EMERGENCYSTATE_MODE\"].isna()][\"TARGET\"].value_counts(normalize=True)\n",
    "# #Here it represents about half our dataset, we will create a \"NA\" variable as well since there is a small deviation from what\n",
    "# #We would have expected\n",
    "\n",
    "# app.loc[app[\"EMERGENCYSTATE_MODE\"].isna(),\"EMERGENCYSTATE_MODE\"] = 'UKN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "602bee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Looking at \"nan\" values in OCCUPATION TYPE\n",
    "# print(len(app[app[\"OCCUPATION_TYPE\"].isna()]))\n",
    "\n",
    "# app[app[\"OCCUPATION_TYPE\"].isna()][\"TARGET\"].value_counts(normalize=True)\n",
    "# #Here it represents about a third of our dataset, we will create a \"NA\" variable as well since there is a deviation from what\n",
    "# #we would have expected\n",
    "\n",
    "# app.loc[app[\"OCCUPATION_TYPE\"].isna(),\"OCCUPATION_TYPE\"] = 'UKN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec06962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Looking at \"nan\" values in NAME_TYPE_SUITE\n",
    "# print(len(app[app[\"NAME_TYPE_SUITE\"].isna()]))\n",
    "# #Only 1292 NA values\n",
    "\n",
    "# #We will replace these rows by the mode\n",
    "# app[\"NAME_TYPE_SUITE\"] = app[\"NAME_TYPE_SUITE\"].fillna(app[\"NAMLE_TYPE_SUITE\"].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bffbad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We can see that WEEKDAY_APPR_PROCESS_START is coded as a string\n",
    "\n",
    "# import time\n",
    "# #Let's convert it into week day number\n",
    "# app[\"WEEKDAY_APPR_PROCESS_START\"] = app[\"WEEKDAY_APPR_PROCESS_START\"].apply(lambda x: time.strptime(x, '%A').tm_wday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "296c309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Verifying that we've dealt with all missing values of categorical variables\n",
    "# for c in app.columns:\n",
    "#     if app[c].dtype == 'object':\n",
    "#         print(app[c].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38c8b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#Summarizing preprocessing of categorical variables\n",
    "def preprocess_cat_vars(df: pd.DataFrame):\n",
    "\n",
    "    df[\"CODE_GENDER\"] = df[\"CODE_GENDER\"].fillna(df[\"CODE_GENDER\"].mode())\n",
    "\n",
    "    df.loc[df[\"EMERGENCYSTATE_MODE\"].isna(),\"EMERGENCYSTATE_MODE\"] = 'UKN'\n",
    "\n",
    "    df.loc[df[\"OCCUPATION_TYPE\"].isna(),\"OCCUPATION_TYPE\"] = 'UKN'\n",
    "\n",
    "    df[\"NAME_TYPE_SUITE\"] = df[\"NAME_TYPE_SUITE\"].fillna(df[\"NAME_TYPE_SUITE\"].mode())\n",
    "\n",
    "    #Let's convert it into week day number\n",
    "    df[\"WEEKDAY_APPR_PROCESS_START\"] = df[\"WEEKDAY_APPR_PROCESS_START\"].apply(lambda x: time.strptime(x, '%A').tm_wday)\n",
    "    \n",
    "    #Replacing 0 values in categorical fields by nan\n",
    "    for c in [\"FONDKAPREMONT_MODE\", \"HOUSETYPE_MODE\", \"WALLSMATERIAL_MODE\"]:\n",
    "        df.loc[df[c] == 0, c] = np.nan\n",
    "    \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d158d",
   "metadata": {},
   "source": [
    "We have finished cleaning up categorical variables, now we will look at numeric variables \n",
    "\n",
    "### 2.2 Cleaning numeric variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae177e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking for outliers \n",
    "\n",
    "#Increasing the number of maximum columns shown\n",
    "pd.options.display.max_columns = 100\n",
    "#app.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9467e58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DAYS_BIRTH, DAYS_REGISTRATION and DAYS_ID_PUBLISH only have negative values\n",
    "# app[\"DAYS_REGISTRATION\"] = abs(app[\"DAYS_REGISTRATION\"])\n",
    "# app[\"DAYS_ID_PUBLISH\"] = abs(app[\"DAYS_ID_PUBLISH\"])\n",
    "# app[\"DAYS_BIRTH\"] = abs(app[\"DAYS_BIRTH\"])\n",
    "\n",
    "# #DAYS EMPLOYED have abherrent values (365243 days, about 1000 years)\n",
    "# app.loc[app[\"DAYS_EMPLOYED\"] > 100000, \"DAYS_EMPLOYED\"] = np.nan\n",
    "# app[\"DAYS_EMPLOYED\"] = abs(app[\"DAYS_EMPLOYED\"])\n",
    "\n",
    "# print(app[\"DAYS_BIRTH\"].min()/365, app[\"DAYS_BIRTH\"].max()/365)\n",
    "# #No outlier data, from 20 to 69 years\n",
    "\n",
    "# def label_age(days_birth):\n",
    "#     age_years = days_birth / 365\n",
    "#     if age_years < 30: return 1\n",
    "#     elif age_years < 40: return 2\n",
    "#     elif age_years < 50: return 3\n",
    "#     elif age_years < 60: return 4\n",
    "#     elif age_years < 70: return 5\n",
    "#     else: return 0\n",
    "    \n",
    "# app[\"AGE_LABEL\"] = app[\"DAYS_BIRTH\"].apply(lambda x: label_age(x))\n",
    "\n",
    "# app = app[app['AMT_INCOME_TOTAL'] < 20000000] # remove an outlier (117 million)\n",
    "\n",
    "# # Calculated features\n",
    "# app['DAYS_EMPLOYED_PCT'] = app['DAYS_EMPLOYED'] / app['DAYS_BIRTH']\n",
    "# app['INCOME_CREDIT_PCT'] = app['AMT_INCOME_TOTAL'] / app['AMT_CREDIT']\n",
    "# app['INCOME_PER_PERSON'] = app['AMT_INCOME_TOTAL'] / app['CNT_FAM_MEMBERS']\n",
    "# app['ANNUITY_INCOME_PCT'] = app['AMT_ANNUITY'] / app['AMT_INCOME_TOTAL']\n",
    "# app['PAYMENT_RATE'] = app['AMT_ANNUITY'] / app['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa11805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcc2fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Turning SK_ID_CURR into an ID field :\n",
    "# app.set_index('SK_ID_CURR', inplace=True)\n",
    "\n",
    "# app.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e7a43",
   "metadata": {},
   "source": [
    "Analysis of the describe() output shows that there is **no clear outlier** in the rest of the numeric data. We can now start handling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e5d2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(app.columns[app.isnull().any()])\n",
    "# #21 columns with NA values\n",
    "\n",
    "# #Dropping rows with more than 50% na values\n",
    "# def drop_na_rows(df: pd.DataFrame, pct: float):\n",
    "#     n = len(df.columns)\n",
    "#     cutoff = n*pct/100 \n",
    "#     df = df[df.isna().sum(axis=1) > cutoff]\n",
    "\n",
    "# drop_na_rows(app, 50)\n",
    "#No row was removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d9c8415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarizing cleaning of numeric variables:\n",
    "\n",
    "def preprocess_num_vars(df: pd.DataFrame,\n",
    "                        quantiles=[25650.0,81000.0,99000.0,112500.0,135000.0,147150.0,162000.0,180000.0,225000.0,270000.0,117000000.0]):\n",
    "    #Setting index\n",
    "    data = df.copy()\n",
    "    data.set_index('SK_ID_CURR', inplace=True)\n",
    "    \n",
    "    #DAYS_BIRTH, DAYS_REGISTRATION and DAYS_ID_PUBLISH only have negative values\n",
    "    data[\"DAYS_REGISTRATION\"] = abs(data[\"DAYS_REGISTRATION\"])\n",
    "    data[\"DAYS_ID_PUBLISH\"] = abs(data[\"DAYS_ID_PUBLISH\"])\n",
    "    data[\"DAYS_BIRTH\"] = abs(data[\"DAYS_BIRTH\"])\n",
    "\n",
    "    #DAYS EMPLOYED have abherrent values (365243 days, about 1000 years)\n",
    "    data[\"DAYS_EMPLOYED_ANOM_FLAG\"] = 0 #Creating anomaly flag\n",
    "    data.loc[data[\"DAYS_EMPLOYED\"] > 100000, \"DAYS_EMPLOYED_ANOM_FLAG\"] = 1 \n",
    "    data.loc[data[\"DAYS_EMPLOYED\"] > 100000, \"DAYS_EMPLOYED\"] = np.nan\n",
    "    data[\"DAYS_EMPLOYED\"] = abs(data[\"DAYS_EMPLOYED\"])\n",
    "\n",
    "    def label_age(days_birth):\n",
    "        age_years = days_birth / 365\n",
    "        if age_years < 30: return 1\n",
    "        elif age_years < 40: return 2\n",
    "        elif age_years < 50: return 3\n",
    "        elif age_years < 60: return 4\n",
    "        elif age_years < 70: return 5\n",
    "        else: return 0\n",
    "\n",
    "    data[\"AGE_LABEL\"] = data[\"DAYS_BIRTH\"].apply(lambda x: label_age(x))\n",
    "\n",
    "    data = data[data['AMT_INCOME_TOTAL'] < 20000000] # remove an outlier (117 million)\n",
    "\n",
    "    \n",
    "    data[\"AMT_INCOME_BIN\"] = pd.cut(data[\"AMT_INCOME_TOTAL\"], bins=quantiles, labels=False)\n",
    "\n",
    "    # Calculated features\n",
    "    data['DAYS_EMPLOYED_PCT'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "    data['INCOME_CREDIT_PCT'] = data['AMT_INCOME_TOTAL'] / data['AMT_CREDIT']\n",
    "    data['INCOME_PER_PERSON'] = data['AMT_INCOME_TOTAL'] / data['CNT_FAM_MEMBERS']\n",
    "    data['ANNUITY_INCOME_PCT'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "    data['PAYMENT_RATE'] = data['AMT_ANNUITY'] / data['AMT_CREDIT']\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdf2193",
   "metadata": {},
   "source": [
    "We have verified that all of our 3 sets are composed only of numeric features and that they have the same number of columns.\n",
    "\n",
    "We will now use **additional features from other dataframes** to increase the performance of our models.\n",
    "\n",
    "### 2.3 Using previous application data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10bb0335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev_app = pd.read_csv(\"Data/previous_application.csv\", sep=\",\")\n",
    "\n",
    "# prev_app.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1df49509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev_app.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7722b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We are interested in DAYS_LAST_DUE (the number of days the borrower has to pay previous applications)\n",
    "# #But there are illogical values (365243 which is equal to 1000 years)\n",
    "# #First we'll replace all the values by nan\n",
    "# prev_app.loc[prev_app.DAYS_LAST_DUE > 300000, \"DAYS_LAST_DUE\"] = np.nan\n",
    "# prev_app.loc[prev_app.DAYS_FIRST_DUE > 300000, \"DAYS_FIRST_DUE\"] = np.nan\n",
    "# prev_app.loc[prev_app.DAYS_LAST_DUE_1ST_VERSION > 300000, \"DAYS_LAST_DUE_1ST_VERSION\"] = np.nan\n",
    "# prev_app.loc[prev_app.DAYS_FIRST_DRAWING > 300000, \"DAYS_FIRST_DRAWING\"] = np.nan\n",
    "# prev_app.loc[prev_app.DAYS_TERMINATION > 300000, \"DAYS_TERMINATION\"] = np.nan\n",
    "\n",
    "# #Defining current amount due, we have to add a negative sign because DAYS_LAST_DUE is negative\n",
    "# prev_app[\"AMT_CURR_DUE\"] = -prev_app[\"AMT_ANNUITY\"]*prev_app[\"DAYS_LAST_DUE\"]/365\n",
    "\n",
    "# prev_app[\"CURR_ANNUITY\"] = 0\n",
    "# prev_app.loc[prev_app[\"DAYS_LAST_DUE\"] < 0, \"CURR_ANNUITY\"] = prev_app[\"AMT_ANNUITY\"]\n",
    "\n",
    "# # Calculated variables\n",
    "# prev_app['APPLICATION_CREDIT_DIF'] = prev_app['AMT_APPLICATION'] - prev_app['AMT_CREDIT']\n",
    "# prev_app['CREDIT_TO_ANNUITY'] = prev_app['AMT_CREDIT'] / prev_app['AMT_ANNUITY']\n",
    "# prev_app['DOWN_PAYMENT_TO_CREDIT'] = prev_app['AMT_DOWN_PAYMENT'] / prev_app['AMT_CREDIT']\n",
    "\n",
    "# prev_app.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "688c8709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Verifying unique values of contract status\n",
    "# prev_app.NAME_CONTRACT_STATUS.unique()\n",
    "# #4 categories, Approved, Refused, Canceled and Unused offer\n",
    "\n",
    "# prev_app[\"AMT_GRANTED\"] = 0\n",
    "# prev_app.loc[prev_app[\"NAME_CONTRACT_STATUS\"] == \"Approved\", \"AMT_GRANTED\"] = prev_app[\"AMT_CREDIT\"]\n",
    "\n",
    "# prev_app.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8326702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregations = {\n",
    "#         'AMT_ANNUITY': ['std', 'mean', 'sum'],\n",
    "#         'AMT_APPLICATION': ['std', 'mean', 'sum'],\n",
    "#         'AMT_CREDIT': ['std', 'mean', 'sum'],\n",
    "#         'AMT_CURR_DUE': ['std', 'mean', 'sum'],\n",
    "#         'CURR_ANNUITY': ['std', 'mean', 'sum'],\n",
    "#         'AMT_DOWN_PAYMENT': ['std', 'mean', 'sum'],\n",
    "#         'AMT_GOODS_PRICE': ['std', 'mean', 'sum'],\n",
    "#         'HOUR_APPR_PROCESS_START': ['std', 'mean'],\n",
    "#         'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "#         'DAYS_DECISION': ['std', 'mean', 'sum'],\n",
    "#         'CNT_PAYMENT': ['mean', 'sum','std'],\n",
    "#         'SK_ID_PREV': ['nunique'],\n",
    "#         'DAYS_TERMINATION': ['mean', 'sum', 'std'],\n",
    "#         'DOWN_PAYMENT_TO_CREDIT': ['sum', 'mean', 'std']\n",
    "#     }\n",
    "\n",
    "# #We will aggregate by SK_ID_CURR and retrieve important information about previous applications :\n",
    "# prev_app_numbers = prev_app.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "\n",
    "# #Renaming columns to remove multi indexing\n",
    "# prev_app_numbers.columns = pd.Index(['APP' + '_' + e[0] + '_' + e[1] for e in prev_app_numbers.columns])\n",
    "\n",
    "# prev_app_numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0969f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creating a dataframe with the number of each different name contract status by SK_ID_CURR\n",
    "# prev_app_status = pd.crosstab(prev_app['SK_ID_CURR'], prev_app['NAME_CONTRACT_STATUS'])\n",
    "\n",
    "# cols = [\"N_PREV_APPROVED\",\"N_PREV_CANCELED\",\"N_PREV_REFUSED\",\"N_PREV_UNUSED\"]\n",
    "# prev_app_status.columns = cols\n",
    "\n",
    "# #Importing the number of unique applications from prev_app_numbers\n",
    "# prev_app_status = pd.merge(prev_app_status, prev_app_numbers[[\"APP_SK_ID_PREV_nunique\"]],\n",
    "#                            how=\"inner\", left_index=True, right_index=True)\n",
    "\n",
    "# for c in cols:\n",
    "#     prev_app_status[c] = prev_app_status[c] / prev_app_status[\"APP_SK_ID_PREV_nunique\"]\n",
    "\n",
    "# prev_app_status = prev_app_status.drop(columns={\"APP_SK_ID_PREV_nunique\"})\n",
    "# prev_app_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "221260cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prev_app_df = pd.merge(prev_app_numbers, prev_app_status, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# prev_app_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df098c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Saving prev_app_df to prevent RAM usage and reduce rerun time\n",
    "# prev_app_df.to_csv(\"Data/prev_app_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcbab37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prev_app_info(X_train, test_set=False, X_test=None, X_val=None, validation_set=False):\n",
    "\n",
    "    #Joining this new data and filling NAs with 0 (since it means there was no previous application)\n",
    "    X_train = pd.merge(X_train, prev_app_df, how='left', left_index=True, right_index=True)\n",
    "    if not test_set:\n",
    "        return X_train\n",
    "    else:\n",
    "        X_test = pd.merge(X_test, prev_app_df, how='left', left_index=True, right_index=True)\n",
    "    if validation_set:\n",
    "        X_val = pd.merge(X_val, prev_app_df, how='left', left_index=True, right_index=True)\n",
    "        return X_train, X_test, X_val\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ebb22",
   "metadata": {},
   "source": [
    "### 2.4 Using Credit Bureau information\n",
    "\n",
    "We also have information about CB for each borrower that we can use to increase the accuracy of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99e28b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bureau = pd.read_csv(\"Data/bureau.csv\", sep=\",\")\n",
    "\n",
    "# bureau.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc29681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bureau.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "724001f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bureau.CREDIT_ACTIVE.unique())\n",
    "# print(bureau.CREDIT_CURRENCY.unique())\n",
    "\n",
    "# len(bureau[bureau.CREDIT_CURRENCY.isna()])\n",
    "# #Credit active is interesting because of the bad debt field\n",
    "# #Currency is also interesting because it could be an indicator to fraudulent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5478dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Calculating new features\n",
    "\n",
    "# #Date differences\n",
    "# bureau['CREDIT_DURATION'] = -bureau['DAYS_CREDIT'] + bureau['DAYS_CREDIT_ENDDATE']\n",
    "# bureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n",
    "\n",
    "# #Day overdue flags:\n",
    "# bureau['BUREAU_IS_DPD'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# bureau['BUREAU_IS_DPD_OVER100'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 100 else 0)\n",
    "                                                                     \n",
    "# #Debt ratio                                                         \n",
    "# bureau['BUREAU_CREDIT_DEBT_RATIO'] = bureau['AMT_CREDIT_SUM_DEBT'] / bureau['AMT_CREDIT_SUM']\n",
    "\n",
    "\n",
    "# #We will now aggreagte over SK_ID_CURR to calculate relevant numeric features \n",
    "\n",
    "# aggregations = {\n",
    "#         'DAYS_CREDIT': ['sum', 'mean', 'std'],\n",
    "#         'DAYS_CREDIT_ENDDATE': ['sum', 'mean', 'std'],\n",
    "#         'CREDIT_DAY_OVERDUE': ['min', 'max', 'sum','mean', 'std'],\n",
    "#         'AMT_CREDIT_MAX_OVERDUE': ['min', 'max', 'sum', 'mean', 'std'],\n",
    "#         'AMT_CREDIT_SUM': ['min', 'max', 'sum', 'mean', 'std'],\n",
    "#         'AMT_CREDIT_SUM_DEBT': ['min', 'max', 'sum', 'mean', 'std'],\n",
    "#         'AMT_CREDIT_SUM_OVERDUE': ['min', 'max', 'sum', 'mean', 'std'],\n",
    "#         'AMT_CREDIT_SUM_LIMIT': ['min', 'max', 'sum', 'mean', 'std'],\n",
    "#         'AMT_ANNUITY': ['min', 'max', 'mean', 'sum', 'std'],\n",
    "#         'CNT_CREDIT_PROLONG': ['sum', 'mean', 'std'],\n",
    "#         'SK_ID_BUREAU': ['count'],\n",
    "#         'DAYS_ENDDATE_FACT': ['min', 'max', 'mean', 'std'],\n",
    "#         'ENDDATE_DIF': ['min', 'max', 'mean', 'std'],\n",
    "#         'BUREAU_CREDIT_DEBT_RATIO': ['min', 'max', 'mean','std'],\n",
    "#         'BUREAU_IS_DPD': ['mean', 'sum', 'std'],\n",
    "#         'BUREAU_IS_DPD_OVER100': ['mean', 'sum', 'std']\n",
    "# } \n",
    "                                                                     \n",
    "# bureau_num = bureau.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "\n",
    "# #Renaming columns to remove multi indexing\n",
    "# bureau_num.columns = pd.Index(['BUREAU' + '_' + e[0] + '_' + e[1] for e in bureau_num.columns])\n",
    "\n",
    "# bureau_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67e88fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We will count the number of CB credits with each of these attributes :\n",
    "# bureau_categ1 = pd.crosstab(bureau['SK_ID_CURR'], bureau['CREDIT_ACTIVE'])\n",
    "# bureau_categ2 = pd.crosstab(bureau['SK_ID_CURR'], bureau['CREDIT_CURRENCY'])\n",
    "\n",
    "# bureau_categ = pd.merge(bureau_categ1, bureau_categ2, how=\"outer\", left_index=True, right_index=True)\n",
    "\n",
    "# cols = ['CB_ACTIVE', 'CB_BAD_DEBT', 'CB_CLOSED', 'CB_SOLD',\n",
    "#                         'CB_CURR1', 'CB_CURR2', 'CB_CURR3', 'CB_CURR4']\n",
    "# bureau_categ.columns = cols\n",
    "\n",
    "# bureau_categ = pd.merge(bureau_categ, bureau_num[[\"BUREAU_SK_ID_BUREAU_count\"]], how=\"inner\", left_index=True, right_index=True)\n",
    "\n",
    "# for c in cols:\n",
    "#     bureau_categ[c] = bureau_categ[c] / bureau_categ[\"BUREAU_SK_ID_BUREAU_count\"]\n",
    "# bureau_categ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6015ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We now load the bureau_balance csv file\n",
    "# bureau_balance = pd.read_csv(\"Data/bureau_balance.csv\", sep=',')\n",
    "\n",
    "# bureau_balance.STATUS.value_counts(normalize=True)\n",
    "\n",
    "# bureau_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95d7f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We create a crosstab to count the number of status type for each sk_id_bureau\n",
    "# bureau_balance_stats = pd.crosstab(bureau_balance['SK_ID_BUREAU'], bureau_balance['STATUS'])\n",
    "\n",
    "# bureau_balance_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1caadbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Counting the number of columns for each sk_id_bureau\n",
    "# bureau_balance_count = bureau_balance[[\"SK_ID_BUREAU\",\"MONTHS_BALANCE\"]].groupby(\"SK_ID_BUREAU\").count()\n",
    "\n",
    "# bureau_balance_count.columns = [\"CB_COUNT\"]\n",
    "\n",
    "# #Renaming the columns for better clarity\n",
    "# cols = [\"CB_DPD_0\",\"CB_DPD_1\",\"CB_DPD_2\",\"CB_DPD_3\",\"CB_DPD_4\",\"CB_DPD_5\",\"CB_BAL_CLOSED\",\"CB_BAL_UKN\"]\n",
    "# bureau_balance_stats.columns=[\"CB_DPD_0\",\"CB_DPD_1\",\"CB_DPD_2\",\"CB_DPD_3\",\"CB_DPD_4\",\"CB_DPD_5\",\"CB_BAL_CLOSED\",\"CB_BAL_UKN\"]\n",
    "\n",
    "# bureau_balance_stats = pd.merge(bureau_balance_stats, bureau_balance_count, how=\"inner\", left_index=True, right_index=True)\n",
    "\n",
    "# for c in cols:\n",
    "#     bureau_balance_stats[c] = bureau_balance_stats[c] / bureau_balance_stats[\"CB_COUNT\"]\n",
    "\n",
    "# bureau_balance_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "179f2a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Joining with the main CB dataframe to retrieve SK_ID_CURR info\n",
    "# bureau_num_bal = pd.merge(bureau_balance_stats, bureau[[\"SK_ID_BUREAU\",\"SK_ID_CURR\"]], how='inner', left_index=True, right_on='SK_ID_BUREAU')\n",
    "\n",
    "# #Creating aggregator\n",
    "# agg_functions = ['min', 'max', 'mean', 'std', 'sum']\n",
    "\n",
    "# aggregations = {\n",
    "#     c: agg_functions for c in bureau_balance_stats.columns\n",
    "# }\n",
    "\n",
    "# #Aggregating by SK_ID_CURR\n",
    "# bureau_num_bal = bureau_num_bal.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "\n",
    "# #Renaming columns to remove multi indexing\n",
    "# bureau_num_bal.columns = pd.Index(['BB' + '_' + e[0] + '_' + e[1] for e in bureau_num_bal.columns])\n",
    "\n",
    "# bureau_num_bal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7286d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bureau_num_bal.info()\n",
    "# #We only have 134k different SK_ID, which is about 40% of our dataset. \n",
    "# #We will fill nulls with 0 because it means that the other SK_ID were not referenced at the Credit Bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a10654e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bureau_num_full = pd.merge(bureau_num, bureau_num_bal, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# bureau_num_full.info()\n",
    "# bureau_num_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4824cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Merging the 2 dataframes with bureau information\n",
    "# bureau_df = pd.merge(bureau_categ, bureau_num_full, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# bureau_df.replace([np.inf, -np.inf], np.nan, inplace=True) #Removing infinite values\n",
    "\n",
    "# bureau_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6798683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Saving bureau_df to reduce RAM usage\n",
    "# bureau_df.to_csv(\"Data/bureau_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "801412f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bureau_info(X_train, test_set=False, X_test=None, X_val=None, validation_set=False):\n",
    "\n",
    "    bureau_df.set_index(\"SK_ID_CURR\", inplace=True)\n",
    "    #Joining this new data\n",
    "    X_train = pd.merge(X_train, bureau_df, how='left', left_index=True, right_index=True)\n",
    "    if not test_set:\n",
    "        return X_train\n",
    "    else:\n",
    "        X_test = pd.merge(X_test, bureau_df, how='left', left_index=True, right_index=True)\n",
    "    if validation_set:\n",
    "        X_val = pd.merge(X_val, bureau_df, how='left', left_index=True, right_index=True)\n",
    "        return X_train, X_test, X_val\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504d3913",
   "metadata": {},
   "source": [
    "### 2.5 Using Cash balance information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87d60842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cash = pd.read_csv(\"Data/POS_CASH_balance.csv\", sep=',')\n",
    "\n",
    "# cash.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea767dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creating late payment flag\n",
    "# cash['LATE_PAYMENT'] = cash['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# cash['POS_IS_DPD_OVER_100'] = cash['SK_DPD'].apply(lambda x: 1 if x >= 100 else 0)\n",
    "\n",
    "# #Creating aggregator\n",
    "# agg_functions = ['min', 'max', 'mean', 'std', 'sum']\n",
    "\n",
    "# #Aggregating on all columns except months_balance and sk_id_prev\n",
    "# aggregations = {\n",
    "#     c: agg_functions for c in cash.drop(columns={\"SK_ID_CURR\",\"SK_ID_PREV\",\"MONTHS_BALANCE\", \"NAME_CONTRACT_STATUS\"}).columns\n",
    "# }\n",
    "\n",
    "# #Adding a nunique count on SK_ID_PREV\n",
    "# aggregations[\"SK_ID_PREV\"] = \"nunique\"\n",
    "\n",
    "# #Aggregating over \"SK_ID_CURR\"\n",
    "# cash_df = cash.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "\n",
    "# #Renaming columns to remove multi indexing\n",
    "# cash_df.columns = pd.Index(['CASH' + '_' + e[0] + '_' + e[1] for e in cash_df.columns])\n",
    "\n",
    "# cash_df.replace([np.inf, -np.inf], np.nan, inplace=True) #Removing infinite values\n",
    "# cash_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b49861c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Saving cash_df to csv to save RAM usage\n",
    "# cash_df.to_csv(\"Data/cash_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29f62ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cash_info(X_train, test_set=False, X_test=None, X_val=None, validation_set=False):\n",
    "\n",
    "    cash_df.set_index(\"SK_ID_CURR\", inplace=True)\n",
    "\n",
    "    #Joining this new data\n",
    "    X_train = pd.merge(X_train, cash_df, how='left', left_index=True, right_index=True)\n",
    "    if not test_set:\n",
    "        return X_train\n",
    "    else:\n",
    "        X_test = pd.merge(X_test, cash_df, how='left', left_index=True, right_index=True)\n",
    "    if validation_set:\n",
    "        X_val = pd.merge(X_val, cash_df, how='left', left_index=True, right_index=True)\n",
    "        return X_train, X_test, X_val\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4ab2a",
   "metadata": {},
   "source": [
    "### 2.6 Using CC Balance information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "789d73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = pd.read_csv(\"Data/credit_card_balance.csv\",sep=\",\")\n",
    "\n",
    "# cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c86a005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Calculating new features\n",
    "# cc['LATE_PAYMENT'] = cc['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# cc['CARD_IS_DPD_OVER_100'] = cc['SK_DPD'].apply(lambda x: 1 if x >= 100 else 0)\n",
    "\n",
    "# #Creating aggregator\n",
    "# agg_functions = ['min', 'max', 'mean', 'std', 'sum']\n",
    "\n",
    "# #Aggregating on all columns except months_balance and sk_id_prev\n",
    "# aggregations = {\n",
    "#     c: agg_functions for c in cc.drop(columns={\"SK_ID_CURR\",\"SK_ID_PREV\",\"MONTHS_BALANCE\", \"NAME_CONTRACT_STATUS\"}).columns\n",
    "# }\n",
    "\n",
    "# #Adding a nunique count on SK_ID_PREV\n",
    "# aggregations[\"SK_ID_PREV\"] = \"nunique\"\n",
    "\n",
    "# #Aggregating over \"SK_ID_CURR\"\n",
    "# cc_df = cc.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "\n",
    "# #Renaming columns to remove multi indexing\n",
    "# cc_df.columns = pd.Index(['CC_BAL' + '_' + e[0] + '_' + e[1] for e in cc_df.columns])\n",
    "\n",
    "# cc_df.replace([np.inf, -np.inf], np.nan, inplace=True) #Removing infinite values\n",
    "\n",
    "# cc_df.head()\n",
    "\n",
    "# # #Investigating possible months balance values\n",
    "# # cc.MONTHS_BALANCE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb3f47c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Saving cc_df to prevent high RAM usage\n",
    "# cc_df.to_csv(\"Data/cc_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30d10fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cc_info(X_train, test_set=False, X_test=None, X_val=None, validation_set=False):\n",
    "\n",
    "    cc_df.set_index(\"SK_ID_CURR\", inplace=True)\n",
    "\n",
    "    #Joining this new data\n",
    "    X_train = pd.merge(X_train, cc_df, how='left', left_index=True, right_index=True)\n",
    "    if not test_set:\n",
    "        return X_train\n",
    "    else:\n",
    "        X_test = pd.merge(X_test, cc_df, how='left', left_index=True, right_index=True)\n",
    "    if validation_set:\n",
    "        X_val = pd.merge(X_val, cc_df, how='left', left_index=True, right_index=True)\n",
    "        return X_train, X_test, X_val\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24cdfe3",
   "metadata": {},
   "source": [
    "### 2.7 Using installment payments information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37c7bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install = pd.read_csv(\"Data/installments_payments.csv\",sep=\",\")\n",
    "\n",
    "# install.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fd812c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Converting the DAYS columns into positive values\n",
    "# install[\"DAYS_INSTALMENT\"] = install[\"DAYS_INSTALMENT\"].apply(lambda x: abs(x))\n",
    "# install[\"DAYS_ENTRY_PAYMENT\"] = install[\"DAYS_ENTRY_PAYMENT\"].apply(lambda x: abs(x))\n",
    "\n",
    "# #Calculating simple differences\n",
    "# install[\"DAYS_DELAY\"] = install[\"DAYS_ENTRY_PAYMENT\"] - install[\"DAYS_INSTALMENT\"]\n",
    "# install['PAID_OVER_AMOUNT'] = install['AMT_PAYMENT'] - install['AMT_INSTALMENT']\n",
    "\n",
    "# #PAID_OVER flag\n",
    "# install['PAID_OVER'] = install['PAID_OVER_AMOUNT'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# #Difference between DPD and Days before due\n",
    "# install['DPD_diff'] = install['DAYS_ENTRY_PAYMENT'] - install['DAYS_INSTALMENT']\n",
    "# install['DBD_diff'] = install['DAYS_INSTALMENT'] - install['DAYS_ENTRY_PAYMENT']\n",
    "\n",
    "# #Late payment ratio\n",
    "# install['LATE_PAYMENT'] = install.apply(lambda x: 1 if x['DPD_diff'] > 0 else 0, axis=1)\n",
    "# install['INSTALMENT_PAYMENT_RATIO'] = install['AMT_PAYMENT'] / install['AMT_INSTALMENT']\n",
    "# install['LATE_PAYMENT_RATIO'] = install.apply(lambda x: x['INSTALMENT_PAYMENT_RATIO'] if x['LATE_PAYMENT'] == 1 else 0, axis=1)\n",
    "\n",
    "# #Over 100 flag\n",
    "# install['INS_IS_DPD_OVER_100'] = install['DPD_diff'].apply(lambda x: 1 if (x >= 100) else 0)\n",
    "\n",
    "# #We have both high negative and positive delay values which indicate early or very late payment\n",
    "# #We will now calculate the difference in percentage between AMT_INSTALMENT and AMT_PAYMENT\n",
    "# install[\"DEFICIT_PCT\"] = (install[\"AMT_INSTALMENT\"] - install[\"AMT_PAYMENT\"])*100/install[\"AMT_INSTALMENT\"]\n",
    "\n",
    "# install.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7481b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Creating aggregator\n",
    "# agg_functions = ['min', 'max', 'mean', 'std', 'sum']\n",
    "\n",
    "# #Aggregating on all columns except sk_id_prev\n",
    "# aggregations = {\n",
    "#     c: agg_functions for c in install.drop(columns={\"SK_ID_PREV\",\"SK_ID_CURR\"}).columns\n",
    "# }\n",
    "\n",
    "# #Adding a nunique count on SK_ID_PREV\n",
    "# aggregations[\"SK_ID_PREV\"] = \"nunique\"\n",
    "\n",
    "# #Aggregating over \"SK_ID_CURR\"\n",
    "# install_df = install.groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "\n",
    "# #Renaming columns to remove multi indexing\n",
    "# install_df.columns = pd.Index(['CC' + '_' + e[0] + '_' + e[1] for e in install_df.columns])\n",
    "\n",
    "\n",
    "# install_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ab5503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving install_df to a csv to prevent repetitive rerun of the program\n",
    "# install_df.to_csv(\"Data/install_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c518a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_install_info(X_train, test_set=False, X_test=None, X_val=None, validation_set=False):\n",
    "\n",
    "    install_df.set_index(\"SK_ID_CURR\", inplace=True)\n",
    "    install_df.replace([np.inf, -np.inf], np.nan, inplace=True) #Removing infinite values\n",
    "\n",
    "    #Joining this new data and filling NAs with 0\n",
    "    X_train = pd.merge(X_train, install_df, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    if not test_set:\n",
    "        return X_train\n",
    "    else:\n",
    "        X_test = pd.merge(X_test, install_df, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    if validation_set:\n",
    "        X_val = pd.merge(X_val, install_df, how='left', left_index=True, right_index=True)\n",
    "        return X_train, X_test, X_val\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f8af61",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "We will now analyse our dataset.\n",
    "\n",
    "### 3.1 Structure analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b77547ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.shape)\n",
    "# print(pd.value_counts(df.dtypes))\n",
    "# df.select_dtypes(exclude='number').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23a87ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Replacing 0 values in categorical fields by nan\n",
    "# for c in [\"FONDKAPREMONT_MODE\", \"HOUSETYPE_MODE\", \"WALLSMATERIAL_MODE\"]:\n",
    "#     df.loc[df[c] == 0, c] = np.nan\n",
    "    \n",
    "# # Check number of duplicates\n",
    "# n_duplicates = df.duplicated().sum()\n",
    "# print(\"Number of duplicates:\",n_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a966fb9",
   "metadata": {},
   "source": [
    "### 3.2 Missing values\n",
    "\n",
    "We will now explore missing values, but data imputation will be performed in a later step after train/test/val split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f752b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "\n",
    "# missing_value_df = pd.DataFrame({'percent_missing': percent_missing})\n",
    "\n",
    "# missing_value_df.sort_values('percent_missing', ascending=False, inplace=True)\n",
    "\n",
    "# print(len(missing_value_df[missing_value_df.percent_missing > 50])) #201 columns with more than 50% NA\n",
    "\n",
    "# missing_value_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0dbe2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plotting missing columns\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.imshow(df.isna(), aspect=\"auto\", interpolation=\"nearest\", cmap=\"gray\")\n",
    "# plt.xlabel(\"Column Number\")\n",
    "# plt.ylabel(\"Sample Number\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5edc172",
   "metadata": {},
   "source": [
    "We can see that for some columns (number ~ 120-150) there is no data for all samples above ~205000\n",
    "\n",
    "Let's look at a representation of missing features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0ee52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(missing_value_df, bins = range(0,110,10))\n",
    "# plt.xlabel(\"Percentage of features missing\")\n",
    "# plt.ylabel(\"Number of columns\")\n",
    "# plt.title(\"Percentage of features missing per number of column\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9010d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns with more than x% na values\n",
    "def drop_na_columns(df: pd.DataFrame, percent: float):\n",
    "    n = len(df)\n",
    "    cutoff = n*percent/100\n",
    "    for c in df.columns:\n",
    "        if len(df[c].dropna()) < cutoff:\n",
    "            df.drop(columns={c}, inplace=True)\n",
    "\n",
    "# app.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff1649f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #We can see that there is a lot of columns with more than 70% na values and we will delete them from our database.\n",
    "# print(df.shape)\n",
    "# drop_na_columns(df, 30)\n",
    "# print(df.shape)\n",
    "# #This removed 155 features!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bcffc7",
   "metadata": {},
   "source": [
    "### 3.3 General Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c8fcbd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generate the number of continuous columns\n",
    "# cols_continuous = df.select_dtypes(include=\"number\").nunique() >= 100\n",
    "\n",
    "# df_continuous = df[cols_continuous[cols_continuous].index]\n",
    "\n",
    "# print(df_continuous.shape)\n",
    "\n",
    "# #sns.pairplot(df_continuous);\n",
    "# #Too many continuous variables to plot pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ecea7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plotting a histogram of continuous variables\n",
    "# from functions import *\n",
    "# df_continuous.histPlotAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06d3bb2",
   "metadata": {},
   "source": [
    "### 3.4 Feature correlation\n",
    "\n",
    "We can now investigate the correlation between our features.\n",
    "Since we have too many features, it is impossible to display a heatmap but we will look at the features with the most correlation.\n",
    "\n",
    "#### 3.4.1 Correlation with target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93c91881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_corr = df.corr()\n",
    "\n",
    "# df_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47670e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_corr = pd.DataFrame(df_corr.TARGET)\n",
    "\n",
    "# #Turning correlation coefficients into absolute values\n",
    "# target_corr[\"TARGET\"] = abs(target_corr[\"TARGET\"])\n",
    "# target_corr.loc[target_corr[\"TARGET\"] == 1, \"TARGET\"] = 0\n",
    "\n",
    "# target_corr = target_corr.sort_values(by=\"TARGET\", ascending=False)\n",
    "# target_corr.head(10).plot(kind='bar', legend=None)\n",
    "# plt.xlabel(\"Feature\")\n",
    "# plt.ylabel(\"Correlation (abs) with TARGET\")\n",
    "# plt.title(\"Top 10 features most correlated with TARGET\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c1365",
   "metadata": {},
   "source": [
    "We can see that EXT_SOURCE 1, 2 and 3 are the features most correlated with TARGET.\n",
    "\n",
    "#### 3.4.2 Inter Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3e7964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a mask to remove the diagonal and the upper triangle.\n",
    "# lower_triangle_mask = np.tril(np.ones(df_corr.shape), k=-1).astype(\"bool\")\n",
    "\n",
    "# #Stack all correlations, after applying the mask\n",
    "# df_corr_stacked = df_corr.where(lower_triangle_mask).stack().sort_values()\n",
    "\n",
    "# # Showing the lowest and highest correlations in the correlation matrix\n",
    "# df_corr = abs(df_corr)\n",
    "# sns.heatmap(df_corr)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5ac0af",
   "metadata": {},
   "source": [
    "We can see that several features are correlated. There are 3 particularly interesting areas of interest in this plot :\n",
    "    \n",
    "- CASH AND CC CORRELATED variables (bottom right)\n",
    "- Correlation between the aggregates of base variables (top left)\n",
    "- APP correlated variables (middle)\n",
    "\n",
    "Since these correlation will negatively impact our model, we will have to remove them from our database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5509975",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4602298",
   "metadata": {},
   "source": [
    "We've now finished cleaning incorrect values. \n",
    "Before starting to perform data imputation, we need to perform a **train/validation/test split**. This will **prevent us from introducing data leakage during the cleaning process**. \n",
    "\n",
    "### 3.1 Performing train / test / validation split\n",
    "\n",
    "We will divide our dataset as such : \n",
    "\n",
    "-  80% train set \n",
    "-  10% validation \n",
    "-  10% test\n",
    "\n",
    "We will be able to revisit this values during the hyperparameter tuning part of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1d6c6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def perform_split(X, y , ID, target_col: str, validation_set: bool, shuffle: bool, random_state: int, test_size: float):\n",
    "\n",
    "    #Splitting train and test sets, we have to add indices to conserve the original index\n",
    "    X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(\n",
    "        X, y, ID, test_size=test_size, stratify=y, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    #Assigning the correct indices (the SK_IDs) to y_test\n",
    "    y_test.index = indices_test\n",
    "    \n",
    "    if validation_set:\n",
    "        #Applying the same function to separate train and validation set\n",
    "        X_train, X_val, y_train, y_val, indices_train, indices_val = train_test_split(\n",
    "            X_train, y_train, indices_train, test_size = test_size/(1-test_size), \n",
    "            shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "        #Assigning the SK IDs to y_train and y_val\n",
    "        y_val.index = indices_val\n",
    "        y_train.index = indices_train\n",
    "        return X_train, y_train, X_test, y_test, X_val, y_val\n",
    "    \n",
    "    y_train.index = indices_train\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d91f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(X_train), len(X_test), len(X_val))\n",
    "#Our test and validation set have the same length and its 10% of the overall length of X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a350f09b",
   "metadata": {},
   "source": [
    "Now that we have performed the split, we can carry on to perform data imputation.\n",
    "\n",
    "These operations will also have to be performed on the test and train_set, so we will create a function that we will be able to apply to the 3 sets.\n",
    "\n",
    "### 3.2 Data Imputation\n",
    "\n",
    "First we will investigate what columns still have missing values. \n",
    "Normally, we have replaced all missing features for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0dbb1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #For ease of use, we will rename X_train to df so we can better replicate our code afterwards\n",
    "# df = X_train.copy()\n",
    "\n",
    "# def check_col_nas_type(df: pd.DataFrame):\n",
    "#     type_cols = []\n",
    "#     #Verifying the type of columns with missing values\n",
    "#     for c in df.columns[df.isna().any()].tolist():\n",
    "#         if ~np.isin(df[c].dtype, type_cols):\n",
    "#             type_cols.append(df[c].dtype)\n",
    "#     return(type_cols)\n",
    "\n",
    "# check_col_nas_type(df)\n",
    "# #This verifies that we only need to perform data imputation on numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "70bc8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loading visualization functions present in the functions.py file\n",
    "# from functions import *\n",
    "\n",
    "# #Visualizing distribution of all numeric variables\n",
    "# histPlotAll(df)\n",
    "\n",
    "# #Apart from HOUR_APPR_PROCESS_START, all numeric variables seem to be not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48b97081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Defining a data imputation function, we will use the NAME_CONTRACT_TYPE as a category_column\n",
    "\n",
    "#This data_imputation script can be improved during the hyperparameter setting phase\n",
    "\n",
    "def data_imputation(df: pd.DataFrame, max_unique_values=3, use_categ_column=False, category_column='NAME_CONTRACT_TYPE'):\n",
    "    \n",
    "    #Creating a copy of our dataset with numeric values to perform KS test\n",
    "    df_imput = df.select_dtypes(include='number')\n",
    "    num_cols = df_imput.columns\n",
    "    df_imput = pd.DataFrame(StandardScaler().fit_transform(df_imput), columns=num_cols).dropna()\n",
    "\n",
    "    #Creating a list of columns with missing values\n",
    "    missing_cols = df.loc[:, df.isna().any()].columns\n",
    "    \n",
    "    #Iterating over columns with missing data\n",
    "    for c in missing_cols:\n",
    "        \n",
    "        #Verifying that we are in a numeric column\n",
    "        if np.isin(c, num_cols):\n",
    "            \n",
    "            #If there are less or equal to max unique values, we will use mode imputation \n",
    "            if len(df[c].unique()) <= max_unique_values:\n",
    "                \n",
    "                if use_categ_column:\n",
    "                            \n",
    "                    #We will create a subset from our categorical variable and perform mode imputation\n",
    "                    for t in df[category_column].unique():\n",
    "                        #Creating subset\n",
    "                        subset = df.loc[df[category_column] == t]\n",
    "\n",
    "                        #Calculating mode of subset\n",
    "                        mode = subset[c].mode().values[0]\n",
    "\n",
    "                        #Applying imputation\n",
    "                        df.loc[(df[c].isna()) & (df[category_column] == t), c] = mode\n",
    "                \n",
    "                else:\n",
    "                    df[c] = df[c].fillna(df[c].mode().values[0])\n",
    "                            \n",
    "            #If we have more numeric values, we will calculate the Kolmogorov Smirnoff pvalue to test for normalization\n",
    "            else:\n",
    "\n",
    "                #Calculating pvalue of KS test\n",
    "                pval = stats.kstest(df_imput[c], 'norm').pvalue\n",
    "                \n",
    "                if pval >= 0.05:\n",
    "                #P value is superior to 0.05, we cannot reject the null hypothesis and thus conclude the variable is\n",
    "                #approximatively normally distributed\n",
    "                #We will use mean imputation on that variable                    \n",
    "                    if use_categ_column:\n",
    "\n",
    "                        for t in df[category_column].unique():\n",
    "                            #Creating subset\n",
    "                            subset = df.loc[df[category_column] == t]\n",
    "\n",
    "                            #Calculating mean based on that subset and our target column\n",
    "                            mean = subset[c].mean()\n",
    "\n",
    "                            #Applying imputation\n",
    "                            df.loc[(df[c].isna()) & (df[category_column] == t), c] = mean\n",
    "\n",
    "                    else:\n",
    "                        df[c] = df[c].fillna(df[c].mean())\n",
    "                            \n",
    "                else:\n",
    "                    \n",
    "                    if use_categ_column:\n",
    "                        \n",
    "                        #P value is inferior to 0.05, we can reject the null hypothesis and thus conclude the variable is\n",
    "                        #not normally distributed\n",
    "                        #We will use median imputation on that variable\n",
    "                        for t in df[category_column].unique():\n",
    "                            #Creating subset\n",
    "                            subset = df.loc[df[category_column] == t]\n",
    "\n",
    "                            #Calculating mean based on that subset and our target column\n",
    "                            med = subset[c].median()\n",
    "\n",
    "                            #Applying imputation\n",
    "                            df.loc[(df[c].isna()) & (df[category_column] == t), c] = med\n",
    "                            \n",
    "                    else:\n",
    "                        df[c] = df[c].fillna(df[c].median())\n",
    "                        \n",
    "         #Categorical column               \n",
    "        else: df[c] = df[c].fillna(df[c].mode().values[0])\n",
    "\n",
    "# #Applying the function to our 3 sets (X_train has been renamed to df)\n",
    "# numeric_data_imputation(df, 'NAME_CONTRACT_TYPE')\n",
    "# numeric_data_imputation(X_test, 'NAME_CONTRACT_TYPE')\n",
    "# numeric_data_imputation(X_val, 'NAME_CONTRACT_TYPE')\n",
    "\n",
    "#Checking for nulls in our 3 sets\n",
    "# for data in [df,X_test,X_val]:\n",
    "#     print(np.count_nonzero(data.isnull()))\n",
    "    \n",
    "#We have no more NA values in all 3 sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb6975",
   "metadata": {},
   "source": [
    "We will now reencode cyclical features.\n",
    "\n",
    "### 3.3 Encoding Cyclical Features\n",
    "\n",
    "We have 2 columns with time features that are cyclical in nature but coded with numbers.\n",
    "\n",
    "- WEEDKAY_APPR_PROCESS_START\n",
    "- HOUR_APPR_PROCESS_START\n",
    "\n",
    "To increase the performance of our algorithm, we will apply a cyclical encoding algorithm to better represent their cyclical nature :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "583ae756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cyclical_vars(df: pd.DataFrame, cyclical_vars=[\"WEEKDAY_APPR_PROCESS_START\", \"HOUR_APPR_PROCESS_START\"]):\n",
    "    for c in cyclical_vars:\n",
    "        #Calculating the number of unique values\n",
    "        n = len(df[c].unique())\n",
    "        #Defining variable names\n",
    "        cos_var = c + '_cos'\n",
    "        sin_var = c + '_sin'\n",
    "        #Calculating cyclical encoder variables\n",
    "        df[sin_var] = np.sin(df[c] * (2*np.pi/n))\n",
    "        df[cos_var] = np.cos(df[c] * (2*np.pi/n))\n",
    "        #Dropping the base columns\n",
    "        df.drop(columns = {c}, inplace=True)\n",
    "\n",
    "# encode_cyclical_vars(df)\n",
    "# encode_cyclical_vars(X_test)\n",
    "# encode_cyclical_vars(X_val)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fab7ff6",
   "metadata": {},
   "source": [
    "### 3.2 Encoding categorical variables\n",
    "\n",
    "Since our algorithms are only able to use numeric variables, we will need to **encode categorical variables**.\n",
    "\n",
    "For variables with a small number of categories, we will perform **One-Hot Encoding**.\n",
    "\n",
    "If there are more than 10 categories, we will perform **Weight of Evidence (WoE) encoding** instead to avoid a sharp increase in the dimensionality of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a274c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import WOEEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "\n",
    "\n",
    "def encode_cat_vars(df: pd.DataFrame, X_train: pd.DataFrame, y_train, max_categ: int, full_encode=None,\n",
    "                    drop_invariant=False, woe_encode=True):\n",
    "    \n",
    "    #Defining a version that ordinal encodes everything\n",
    "    if full_encode == 'ordinal':\n",
    "        ord_enc = OrdinalEncoder(drop_invariant=drop_invariant, return_df=True).fit(X_train)\n",
    "        df = ord_enc.transform(df)\n",
    "        return df\n",
    "    \n",
    "    #Defining an encoder that woe_encodes everything\n",
    "    if full_encode == 'woe':\n",
    "        woe_encoder = WOEEncoder(drop_invariant=drop_invariant, return_df=True).fit(X_train, y_train)\n",
    "        df = woe_encoder.transform(df)\n",
    "        return df\n",
    "    \n",
    "    if full_encode == 'ohe':\n",
    "        ohe_encoder = OneHotEncoder(return_df= True, drop_invariant=drop_invariant).fit(X_train)\n",
    "        df = ohe_encoder.transform(df)\n",
    "        return df\n",
    "        \n",
    "    woe_cols = []\n",
    "    ohe_cols = []\n",
    "    label_cols = []\n",
    "    for c in X_train.columns:\n",
    "        \n",
    "        #Keeping only categorical columns\n",
    "        if not np.issubdtype(X_train[c].dtype,np.number):\n",
    "            \n",
    "            #If only 2 categories, performing Label encoding\n",
    "            if len(X_train[c].unique()) == 2:\n",
    "                label_cols.append(c)\n",
    "            \n",
    "            #If more than X categories, performing WOE encoding\n",
    "            elif len(X_train[c].unique()) >= max_categ:\n",
    "                woe_cols.append(c)\n",
    "            \n",
    "            else: \n",
    "                #One hot encoding and remove the original column\n",
    "                ohe_cols.append(c)\n",
    "                \n",
    "    #Defining Binary Encoder based on the train dataset and applying it to df\n",
    "    bin_enc = BinaryEncoder(cols= label_cols, drop_invariant=drop_invariant, return_df=True).fit(X_train)\n",
    "    X_train_encoded = bin_enc.transform(X_train)\n",
    "    df = bin_enc.transform(df)\n",
    "    \n",
    "    if woe_encode:\n",
    "        #Defining WOE Encoder and fitting it to the TRAIN dataset\n",
    "        woe_encoder = WOEEncoder(cols = woe_cols, drop_invariant=drop_invariant, return_df=True).fit(X_train_encoded, y_train)\n",
    "        X_train_encoded = woe_encoder.transform(X_train_encoded)\n",
    "        #Fitting the encoder to the selected dataframe\n",
    "        df = woe_encoder.transform(df)\n",
    "    else: #Perform label (ordinal) encoding\n",
    "        label_encoder = LabelEncoder(cols=woe_cols, drop_invariant=drop_invariant, return_df=True).fit(X_train_encoded)\n",
    "        X_train_encoded = label_encoder.transform(X_train_encoded)\n",
    "        df = label_encoder.transform(df)\n",
    "    \n",
    "    #Performing one hot encoding on selected columns\n",
    "    ohe_encoder = OneHotEncoder(cols=ohe_cols, return_df= True, drop_invariant=drop_invariant).fit(X_train_encoded)\n",
    "    df = ohe_encoder.transform(df)\n",
    "    \n",
    "    \n",
    "    del X_train_encoded\n",
    "    return df\n",
    "\n",
    "#Just a reminder that once again df = X_train\n",
    "#We apply all this function to our 3 sets\n",
    "# X_test = encode_cat_vars(X_test, df, y_train, 10)\n",
    "# X_val = encode_cat_vars(X_val, df, y_train, 10)\n",
    "# df = encode_cat_vars(df, df, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d3b92315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_dtypes(df: pd.DataFrame):\n",
    "#     type_cols = []\n",
    "#     for c in df.columns:\n",
    "#         if not np.isin(df[c].dtype, type_cols):\n",
    "#             type_cols.append(df[c].dtype)\n",
    "#     print(type_cols)\n",
    "\n",
    "# check_dtypes(df)\n",
    "# check_dtypes(X_test)\n",
    "# check_dtypes(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8d47e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.shape, X_test.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db19b86",
   "metadata": {},
   "source": [
    "## 4 Resampling our training dataset\n",
    "\n",
    "As we've seen at the beginning of this part, our dataset has a very big imbalance with 92% of rows with the TARGET = 0 and only 8% with the Target variable equal to 1.\n",
    "\n",
    "To reduce this imbalance, we will perform oversampling on our minority class.\n",
    "\n",
    "Of course, **oversampling will only be performed on our train set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98acd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing imblearn to be able to apply different kinds of oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "def over_sample_train(X_train, y_train, method='ADASYN'):\n",
    "    \n",
    "    if method == 'SMOTE':\n",
    "        #Importing the SMOTE algorithm with default values\n",
    "        sm = SMOTE()\n",
    "\n",
    "        #Generating our resampled dataset\n",
    "        X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    elif method == 'SVMSMOTE':\n",
    "        svm = SVMSMOTE()\n",
    "        #Generating our resampled dataset\n",
    "        X_train_res, y_train_res = svm.fit_resample(X_train, y_train)\n",
    "        \n",
    "    else:\n",
    "        ada = ADASYN()\n",
    "        #Generating our resampled dataset\n",
    "        X_train_res, y_train_res = ada.fit_resample(X_train, y_train)\n",
    "    \n",
    "    return X_train_res, y_train_res, X_train, y_train\n",
    "        \n",
    "\n",
    "# print(X_train_res.shape)\n",
    "# print(y_train_res.value_counts())\n",
    "# #We have successfully removed the imbalance from our dataset and equalized the number of observations for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cdd5eb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Renaming the resampled variables for ease of use\n",
    "# X_train_initial = df.copy()\n",
    "# y_train_initial = y_train\n",
    "\n",
    "# X_train = X_train_res.copy()\n",
    "# y_train = y_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0dce2c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          _i71:  4.4 KiB\n",
      "                          _i73:  3.1 KiB\n",
      "                          _i31:  2.1 KiB\n",
      "                          _i18:  1.9 KiB\n",
      "                          _i51:  1.5 KiB\n",
      "                          _i14:  1.4 KiB\n",
      "                          _i21:  1.3 KiB\n",
      "                          _i67:  1.2 KiB\n",
      "                          _i23:  1.1 KiB\n",
      "                           _i1:  1.1 KiB\n",
      "                           _ii:  1.1 KiB\n",
      "                          _i76:  1.1 KiB\n",
      "                 SimpleImputer:  1.0 KiB\n",
      "                StandardScaler:  1.0 KiB\n",
      "                    WOEEncoder:  1.0 KiB\n",
      "                 OneHotEncoder:  1.0 KiB\n",
      "                 BinaryEncoder:  1.0 KiB\n",
      "                OrdinalEncoder:  1.0 KiB\n",
      "                         SMOTE:  1.0 KiB\n",
      "                      SVMSMOTE:  1.0 KiB\n"
     ]
    }
   ],
   "source": [
    "#Deleting some variables to clear memory\n",
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:20]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf55fe3",
   "metadata": {},
   "source": [
    "Now that we have resampled our dataset, we want to perform **feature selection** to reduce the number of features and prevent overfitting.\n",
    "\n",
    "## 5. Feature Selection\n",
    "\n",
    "### 5.1 Removing low variance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e2d2c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature selection using a variance threshold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def perform_variance_selection(X_train, X_test, X_val=None, validation_set=False, threshold=(0.02)):\n",
    "    \n",
    "    initial_cols = X_train.columns\n",
    "    #We select 2% as our variance threshold, but this is a hyperparameter that we will be able to optimize later\n",
    "    sel = VarianceThreshold(threshold=threshold)\n",
    "    sel.fit(X_train)\n",
    "    #Using our selector to remove columns from our 3 sets\n",
    "    X_train_sel = sel.transform(X_train)\n",
    "    X_test_sel = sel.transform(X_test)\n",
    "    if validation_set:\n",
    "        X_val_sel = sel.transform(X_val)\n",
    "\n",
    "    #Creating a list of encoded columns to preserve their names\n",
    "    i = 0\n",
    "    #Retrieving the boolean values for each column (is the column kept or not)\n",
    "    boolean_cols = sel.get_support()\n",
    "    encoded_cols = []\n",
    "    for i in range(len(initial_cols)):\n",
    "        if boolean_cols[i] == True:\n",
    "            encoded_cols.append(initial_cols[i])\n",
    "        i += 1\n",
    "\n",
    "    #The selector has transformed our dataframes into np array, let's turn them back into a DataFrame\n",
    "    X_train = pd.DataFrame(X_train_sel, columns=encoded_cols)\n",
    "    X_test = pd.DataFrame(X_test_sel, columns=encoded_cols)\n",
    "    \n",
    "    if validation_set:\n",
    "        X_val = pd.DataFrame(X_val_sel, columns=encoded_cols)\n",
    "        return X_train, X_test, X_val\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f331561",
   "metadata": {},
   "source": [
    "### 5.2 Removing highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c0fd2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to list features that are correlated\n",
    "# Adds the first of the correlated pair only (not both)\n",
    "def correlatedFeatures(dataset, threshold):\n",
    "    correlated_columns = set()\n",
    "    correlations = dataset.corr()\n",
    "    for i in range(len(correlations)):\n",
    "        for j in range(i):\n",
    "            if abs(correlations.iloc[i,j]) > threshold:\n",
    "                correlated_columns.add(correlations.columns[i])\n",
    "    return correlated_columns\n",
    "\n",
    "# cf = correlatedFeatures(X_train, 0.85)\n",
    "# cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dbaeaabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Removing our highly correlated features\n",
    "# X_train = X_train.drop(cf, axis=1)\n",
    "# X_test = X_test.drop(cf, axis=1)\n",
    "# X_val = X_val.drop(cf, axis=1)\n",
    "\n",
    "# print(X_train.shape, X_test.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9b2e62",
   "metadata": {},
   "source": [
    "### 5.3 Selecting best features\n",
    "\n",
    "We will now use the Kbest algorithm to select the X best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cdff92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "def perform_kbest_selection(X_train, X_test, y_train, k: int):\n",
    "\n",
    "    kbest = SelectKBest(score_func=f_regression, k=k)\n",
    "    kbest.fit(X_train, y_train)\n",
    "    X_train_sel = kbest.transform(X_train)\n",
    "    X_test_sel = kbest.transform(X_test)\n",
    "    \n",
    "    return X_train_sel, X_test_sel\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cac17d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sel = kbest.transform(X_train)\n",
    "# X_val_sel = kbest.transform(X_val)\n",
    "# X_test_sel = kbest.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdce2ec",
   "metadata": {},
   "source": [
    "### 5.4 Compoud Selector Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3beebfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    "\n",
    "def select_features(X_train, X_test, y_train, var_threshold=(0.02), corr_threshold=0.9, k=10,\n",
    "                    unique_select=None, max_boruta_iter=30):\n",
    "    \n",
    "    if unique_select == 'boruta':\n",
    "        rfc = RandomForestClassifier(random_state=1, n_estimators=1000, max_depth=5)\n",
    "        boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1, max_iter=max_boruta_iter)\n",
    "        boruta_selector.fit(np.array(X_train), np.array(y_train)) \n",
    "        \n",
    "        X_important_train = boruta_selector.transform(np.array(X_train))\n",
    "        X_important_test = boruta_selector.transform(np.array(X_test))\n",
    "        \n",
    "        return X_important_train, X_important_test\n",
    "    \n",
    "    elif unique_select == 'kbest':\n",
    "        return perform_kbest_selection(X_train, X_test, y_train, k)\n",
    "    \n",
    "    if not corr_threshold == 0:\n",
    "        cf = correlatedFeatures(X_train, corr_threshold)\n",
    "        X_train = X_train.drop(cf, axis=1)\n",
    "        X_test = X_test.drop(cf, axis=1)\n",
    "        if unique_select == 'correlation':\n",
    "            return X_train_sel, X_test_sel\n",
    "\n",
    "    if not var_threshold == 0:\n",
    "        X_train_sel, X_test_sel = perform_variance_selection(X_train, X_test, threshold=var_threshold)\n",
    "        \n",
    "        if unique_select == 'variance':\n",
    "            return X_train_sel, X_test_sel\n",
    "        \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973771d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 6. Model training\n",
    "\n",
    "The client asked for an **easy to interpret** model with an **indication of the importance of each variable** in determining the probability outcome. \n",
    "\n",
    "We will thus compare and tune the 2 following models:\n",
    "\n",
    "- A **Logistic Regression model**\n",
    "- A **Decision Tree Classifier**\n",
    "\n",
    "### 6.1 Selecting a Performance Metric\n",
    "\n",
    "Our task is to try to detect as many \"bad borrowers\" as possible while avoiding false negatives and losing too many clients.\n",
    "\n",
    "My interpretation is that we want to strike the best balance between **precision and recall**, so we will use the **ROC AUC SCORE** as the performance metric for this project.\n",
    "\n",
    "### 6.2 Calculating a Baseline\n",
    "\n",
    "For this project, the baseline will be a model that predicts that **we can lend money to all borrowers** (TARGET = 0).\n",
    "\n",
    "Let's calculate the ROC AUC, accuracy and precision for such a model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "679ce1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    282686\n",
       "1     24825\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset \n",
    "df = pd.read_csv(\"Data/application_train.csv\", sep=\",\")\n",
    "\n",
    "df[\"TARGET\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5ec35988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC : 0.5\n",
      "Accuracy: 0.9192711805431351\n",
      "Precision: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Calculating ROC AUC\n",
    "from sklearn.metrics import roc_auc_score, precision_score, accuracy_score\n",
    "y = df[\"TARGET\"]\n",
    "X = df.drop(columns={\"TARGET\"})\n",
    "#Creating y_predict with the same size as y but only negative values\n",
    "y_predict = pd.DataFrame(y)\n",
    "y_predict[\"TARGET\"] = 0\n",
    "y_predict = y_predict.squeeze()\n",
    "\n",
    "print(\"ROC :\",roc_auc_score(y, y_predict))\n",
    "print(\"Accuracy:\", accuracy_score(y, y_predict))\n",
    "print(\"Precision:\",precision_score(y, y_predict, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668209fa",
   "metadata": {},
   "source": [
    "As we can see, our model has a ROC of 0.5 and a very high accuracy of 92%, but our precision is 0 since it doesn't detect any potentially \"bad\" borrowers.\n",
    "\n",
    "### 6.3 Preprocessing Pipeline\n",
    "\n",
    "We will create the preprocessing pipeline below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3abe6bf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before na removal: 508\n",
      "Number of features after na removal: 353\n"
     ]
    }
   ],
   "source": [
    "#Loading dataframes\n",
    "df = pd.read_csv(\"Data/application_train.csv\")\n",
    "prev_app_df = pd.read_csv(\"Data/prev_app_df.csv\")\n",
    "bureau_df = pd.read_csv(\"Data/bureau_df.csv\")\n",
    "cash_df = pd.read_csv(\"Data/cash_df.csv\")\n",
    "cc_df = pd.read_csv(\"Data/cc_df.csv\")\n",
    "install_df = pd.read_csv(\"Data/install_df.csv\") \n",
    "\n",
    "#Preprocessing\n",
    "preprocess_cat_vars(df)\n",
    "df = preprocess_num_vars(df)\n",
    "\n",
    "#Loading information from external csv files\n",
    "df = load_prev_app_info(df)\n",
    "df = load_bureau_info(df)\n",
    "df = load_cash_info(df)\n",
    "df = load_cc_info(df)\n",
    "df = load_install_info(df)\n",
    "\n",
    "#Na removal\n",
    "print(\"Number of features before na removal:\", len(df.columns))\n",
    "drop_na_columns(df, 30)\n",
    "print(\"Number of features after na removal:\", len(df.columns))\n",
    "\n",
    "\n",
    "#Encoding cyclical vars\n",
    "encode_cyclical_vars(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ab79ad91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding cat vars (246007, 354) (30751, 354)\n",
      "Finished encoding variables (246007, 366) (30751, 366)\n"
     ]
    }
   ],
   "source": [
    "#Performing train-test split\n",
    "y = df[\"TARGET\"]\n",
    "X = df.drop(columns={\"TARGET\"})\n",
    "ID = df.index\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = perform_split(X, y, ID, target_col='TARGET',\n",
    "                                                 validation_set=True, shuffle=True, random_state=10, test_size=0.1)\n",
    "\n",
    "# #Performing data imputation\n",
    "data_imputation(X_train)\n",
    "data_imputation(X_test)\n",
    "data_imputation(X_val)\n",
    "\n",
    "#Encoding variables\n",
    "print(\"Encoding cat vars\",X_train.shape, X_test.shape)\n",
    "X_test = encode_cat_vars(X_test, X_train, y_train, max_categ=5, full_encode=False)\n",
    "X_val = encode_cat_vars(X_val, X_train, y_train, max_categ=5, full_encode=False)\n",
    "X_train = encode_cat_vars(X_train, X_train, y_train, max_categ=5, full_encode=False)\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1)\n",
    "X_train, X_val = X_train.align(X_val, join='left', axis=1)\n",
    "print(\"Finished encoding variables\",X_train.shape, X_test.shape)\n",
    "\n",
    "#Oversampling\n",
    "X_train, y_train, X_train_init, y_train_init = over_sample_train(X_train, y_train)\n",
    "\n",
    "#Feature selection\n",
    "X_train, X_test, X_val = perform_variance_selection(X_train, X_test, X_val, validation_set=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0c552f",
   "metadata": {},
   "source": [
    "### 6.4 First Logistic Regression Model\n",
    "\n",
    "Now that've defined our preprocessing pipeline, we will use a Logistic regression as a first model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d832bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "202c9332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression results\n",
      "TRAIN:\n",
      "ROC AUC train : 0.93361\n",
      "----------------------\n",
      "TEST:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95     56537\n",
      "           1       0.29      0.10      0.15      4965\n",
      "\n",
      "    accuracy                           0.91     61502\n",
      "   macro avg       0.61      0.54      0.55     61502\n",
      "weighted avg       0.87      0.91      0.89     61502\n",
      "\n",
      "[[55319  1218]\n",
      " [ 4472   493]]\n",
      "ROC AUC test : 0.53888\n"
     ]
    }
   ],
   "source": [
    "#We need to scale the dataset before applying Logistic Regression because sklearn log_r includes L2 regularization\n",
    "pipe_lr = Pipeline([('scaler', StandardScaler()), \n",
    "                    ('log_r', LogisticRegression(max_iter = 3000))])\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "train_predictions = pipe_lr.predict(X_train)\n",
    "test_predictions = pipe_lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression results\")\n",
    "print(\"TRAIN:\")\n",
    "print(\"ROC AUC train : {:.5f}\".format(roc_auc_score(y_train, train_predictions)))\n",
    "print(\"----------------------\")\n",
    "print(\"TEST:\")\n",
    "print(classification_report(y_test, test_predictions))\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "print(\"ROC AUC test : {:.5f}\".format(roc_auc_score(y_test, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "870242d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def logr_classifier(X_train, X_test):\n",
    "    #We need to scale the dataset before applying Logistic Regression because sklearn log_r includes L2 regularization\n",
    "    pipe_lr = Pipeline([('scaler', StandardScaler()), \n",
    "                        ('log_r', LogisticRegression(max_iter = 3000))])\n",
    "\n",
    "    pipe_lr.fit(X_train, y_train)\n",
    "    train_predictions = pipe_lr.predict(X_train)\n",
    "    test_predictions = pipe_lr.predict(X_test)\n",
    "\n",
    "    roc_train = roc_auc_score(y_train, train_predictions) \n",
    "    roc_test = roc_auc_score(y_test, test_predictions)\n",
    "    \n",
    "    return roc_train, roc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9a168",
   "metadata": {},
   "source": [
    "The ROC AUC is barely better than the baseline model. Hopefully we will be able to improve those results with hyperparameter tuning and by refining our feature engineering\n",
    "\n",
    "### 6.5 First Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0c3227d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression results\n",
      "TRAIN:\n",
      "ROC AUC train : 1.00000\n",
      "----------------------\n",
      "TEST:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     56537\n",
      "           1       0.14      0.19      0.16      4965\n",
      "\n",
      "    accuracy                           0.83     61502\n",
      "   macro avg       0.53      0.54      0.53     61502\n",
      "weighted avg       0.86      0.83      0.85     61502\n",
      "\n",
      "[[50370  6167]\n",
      " [ 3997   968]]\n",
      "ROC AUC test : 0.54294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pipe_dtc = Pipeline([('scaler', StandardScaler()), \n",
    "                    ('dtc', DecisionTreeClassifier())])\n",
    "\n",
    "pipe_dtc.fit(X_train, y_train)\n",
    "train_predictions = pipe_dtc.predict(X_train)\n",
    "test_predictions = pipe_dtc.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression results\")\n",
    "print(\"TRAIN:\")\n",
    "print(\"ROC AUC train : {:.5f}\".format(roc_auc_score(y_train, train_predictions)))\n",
    "print(\"----------------------\")\n",
    "print(\"TEST:\")\n",
    "print(classification_report(y_test, test_predictions))\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "print(\"ROC AUC test : {:.5f}\".format(roc_auc_score(y_test, test_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e70d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def dt_classifier(X_train, X_test):\n",
    "    \n",
    "    pipe_dtc = Pipeline([('scaler', StandardScaler()), \n",
    "                    ('dtc', DecisionTreeClassifier())])\n",
    "\n",
    "    pipe_dtc.fit(X_train, y_train)\n",
    "    train_predictions = pipe_dtc.predict(X_train)\n",
    "    test_predictions = pipe_dtc.predict(X_test)\n",
    "    \n",
    "    roc_train = roc_auc_score(y_train, train_predictions) \n",
    "    roc_test = roc_auc_score(y_test, test_predictions)\n",
    "    \n",
    "    return roc_train, roc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6bd60",
   "metadata": {},
   "source": [
    "Unsurprisingly, the **Decision Tree is overfitting** with a ROC AUC train of 1 but a ROC AUC test of 0.54.\n",
    "\n",
    "We will begin by tuning the hyperparameters on the Logistic Regression algorithm that seems to be more promising for now.\n",
    "\n",
    "## 7. Model Performance Tuning\n",
    "\n",
    "The first hyperparameter we will tune is the Scaler applied to the dataset.\n",
    "\n",
    "### 7.1 Scaler selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ead8594a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2101fde1984fc78647447ec277fd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "K:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9329825165342922 0.5382172698049384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\project_4\\lib\\site-packages\\daal4py\\sklearn\\linear_model\\logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5319372387519463 0.532111608396478\n",
      "0.932308874436408 0.5366189704149268\n",
      "0.6204867371392584 0.6026036124716445\n",
      "0.9438856417351269 0.5262385679241098\n",
      "0.9328230320941914 0.5385976815514152\n",
      "0.5185754509740282 0.5205980340392189\n",
      "0.9319729043453541 0.5369674431996613\n",
      "0.616883721871937 0.6126048242530014\n",
      "0.9441737804275112 0.5280335012882306\n",
      "0.9326874989034784 0.5373416704544943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\project_4\\lib\\site-packages\\daal4py\\sklearn\\linear_model\\logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5639550055064347 0.5647480677606044\n",
      "0.9319049115898037 0.5361618336636874\n",
      "0.616277733840591 0.6090616915690784\n",
      "0.9445381967463051 0.5275033781481435\n"
     ]
    }
   ],
   "source": [
    "#Import tqdm to visualize algorithm run\n",
    "from tqdm.notebook import tqdm,tnrange\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer, PowerTransformer\n",
    "\n",
    "#Creating K-fold validation leaves\n",
    "k = 3\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "scores = []\n",
    "\n",
    "#Defining the Scalers\n",
    "scalers = [[StandardScaler(), \"Standard\"], [RobustScaler(), \"Robust\"], [MinMaxScaler(), \"MinMax\"],\n",
    "           [Normalizer(), \"Normalizer\"], [PowerTransformer(), \"PowerTransformer\"]]\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(df), desc='K', total=k):\n",
    "    train = df.loc[df.index.isin(train_index)]\n",
    "    test  = df.loc[df.index.isin(test_index)]\n",
    "    y_train_cv = train[\"TARGET\"]\n",
    "    y_test_cv = test[\"TARGET\"]\n",
    "    X_train_cv = train.drop(columns={\"TARGET\"})\n",
    "    X_test_cv = test.drop(columns={\"TARGET\"})\n",
    "    #Performing data imputation\n",
    "    data_imputation(X_train_cv)\n",
    "    data_imputation(X_test_cv)\n",
    "\n",
    "    #Encoding variables\n",
    "    X_test_cv = encode_cat_vars(X_test_cv, X_train_cv, y_train_cv, max_categ=5, full_encode=False)\n",
    "    X_train_cv = encode_cat_vars(X_train_cv, X_train_cv, y_train_cv, max_categ=5, full_encode=False)\n",
    "    X_train_cv, X_test_cv = X_train_cv.align(X_test_cv, join='left', axis=1)\n",
    "\n",
    "    #Oversampling\n",
    "    X_train_cv, y_train_cv, X_train_init, y_train_init = over_sample_train(X_train_cv, y_train_cv)\n",
    "\n",
    "    #Feature selection\n",
    "    X_train_cv, X_test_cv = perform_variance_selection(X_train_cv, X_test_cv)\n",
    "    \n",
    "    for scaler in scalers:\n",
    "        pipe_lr = Pipeline([('scaler', scaler[0]), \n",
    "                    ('log_r', LogisticRegression(max_iter = 3000))])\n",
    "        \n",
    "        pipe_lr.fit(X_train_cv, y_train_cv)\n",
    "        train_predictions = pipe_lr.predict(X_train_cv)\n",
    "        test_predictions = pipe_lr.predict(X_test_cv)\n",
    "        roc_train = roc_auc_score(y_train_cv, train_predictions) \n",
    "        roc_test = roc_auc_score(y_test_cv, test_predictions)\n",
    "        print(roc_train, roc_test)\n",
    "        scores.append({'Scaler': scaler[1], 'ROC AUC train': roc_train, 'ROC AUC test': roc_test })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7885e397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1177.12x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Converting our scores array into a Dataframe    \n",
    "scores = pd.DataFrame(scores)\n",
    "\n",
    "#Selecting average ROC AUC Score and accuracy by model\n",
    "scores = scores.groupby(\"Scaler\").mean().reset_index().sort_values(by=\"ROC AUC test\", ascending=False)\n",
    "\n",
    "scores_melt = pd.melt(scores, id_vars='Scaler')\n",
    "sns.set(rc={'figure.figsize':(20,15)})\n",
    "sns.catplot(x='Scaler', y='value', hue='variable', data=scores_melt, kind='bar', height = 10)\n",
    "plt.title(\"ROC AUC Scores of LogR for different Scalers\")\n",
    "plt.xlabel(\"Scaler\")\n",
    "plt.ylabel(\"ROC AUC SCORE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c5c1f184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20688c4287d24a049536170cfa88b0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "K:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.539715092469804\n",
      "1.0 0.5384978156051797\n",
      "1.0 0.5362095901683857\n",
      "1.0 0.5266339073558628\n",
      "1.0 0.5392030317247762\n",
      "1.0 0.5296240253693333\n",
      "1.0 0.5318397538250785\n",
      "1.0 0.5308266527206404\n",
      "1.0 0.5317232421619243\n",
      "1.0 0.5314914123066875\n",
      "1.0 0.5384507518011589\n",
      "1.0 0.5390317144332292\n",
      "1.0 0.5389691545797378\n",
      "1.0 0.5245938298441947\n",
      "1.0 0.5425404119684134\n"
     ]
    }
   ],
   "source": [
    "#Import tqdm to visualize algorithm run\n",
    "from tqdm.notebook import tqdm,tnrange\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer, PowerTransformer\n",
    "\n",
    "#Creating K-fold validation leaves\n",
    "k = 3\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "scores_dt = []\n",
    "\n",
    "#Defining the Scalers\n",
    "scalers = [[StandardScaler(), \"Standard\"], [RobustScaler(), \"Robust\"], [MinMaxScaler(), \"MinMax\"],\n",
    "           [Normalizer(), \"Normalizer\"], [PowerTransformer(), \"PowerTransformer\"]]\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(df), desc='K', total=k):\n",
    "    train = df.loc[df.index.isin(train_index)]\n",
    "    test  = df.loc[df.index.isin(test_index)]\n",
    "    y_train_cv = train[\"TARGET\"]\n",
    "    y_test_cv = test[\"TARGET\"]\n",
    "    X_train_cv = train.drop(columns={\"TARGET\"})\n",
    "    X_test_cv = test.drop(columns={\"TARGET\"})\n",
    "    #Performing data imputation\n",
    "    data_imputation(X_train_cv)\n",
    "    data_imputation(X_test_cv)\n",
    "\n",
    "    #Encoding variables\n",
    "    X_test_cv = encode_cat_vars(X_test_cv, X_train_cv, y_train_cv, max_categ=5, full_encode=False)\n",
    "    X_train_cv = encode_cat_vars(X_train_cv, X_train_cv, y_train_cv, max_categ=5, full_encode=False)\n",
    "    X_train_cv, X_test_cv = X_train_cv.align(X_test_cv, join='left', axis=1)\n",
    "\n",
    "    #Oversampling\n",
    "    X_train_cv, y_train_cv, X_train_init, y_train_init = over_sample_train(X_train_cv, y_train_cv)\n",
    "\n",
    "    #Feature selection\n",
    "    X_train_cv, X_test_cv = perform_variance_selection(X_train_cv, X_test_cv)\n",
    "    \n",
    "    for scaler in scalers:\n",
    "        pipe_lr = Pipeline([('scaler', scaler[0]), \n",
    "                    ('log_r', DecisionTreeClassifier())])\n",
    "        \n",
    "        pipe_lr.fit(X_train_cv, y_train_cv)\n",
    "        train_predictions = pipe_lr.predict(X_train_cv)\n",
    "        test_predictions = pipe_lr.predict(X_test_cv)\n",
    "        roc_train = roc_auc_score(y_train_cv, train_predictions) \n",
    "        roc_test = roc_auc_score(y_test_cv, test_predictions)\n",
    "        print(roc_train, roc_test)\n",
    "        scores_dt.append({'Scaler': scaler[1], 'ROC AUC train': roc_train, 'ROC AUC test': roc_test })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "822c0da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1158.62x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Converting our scores array into a Dataframe    \n",
    "scores_dt = pd.DataFrame(scores_dt)\n",
    "\n",
    "#Selecting average ROC AUC Score and accuracy by model\n",
    "scores_dt = scores_dt.groupby(\"Scaler\").mean().reset_index().sort_values(by=\"ROC AUC test\", ascending=False)\n",
    "\n",
    "scores_melt = pd.melt(scores_dt, id_vars='Scaler')\n",
    "sns.set(rc={'figure.figsize':(20,15)})\n",
    "sns.catplot(x='Scaler', y='value', hue='variable', data=scores_melt, kind='bar', height = 10)\n",
    "plt.title(\"ROC AUC Scores of LogR for different Scalers\")\n",
    "plt.xlabel(\"Scaler\")\n",
    "plt.ylabel(\"ROC AUC SCORE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f56879",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 7.2 Model Hyperparameter tuning\n",
    "\n",
    "Now that we've selected ideal scalers for both models, we will tune hyperparameters to increase our performance indicator ==> ROC AUC. We will use the sklearn **Grid Search Cross Valided** package to perform this hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926a702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 42 candidates, totalling 42 fits\n",
      "[CV 1/1; 1/42] START log_r__C=0.001, log_r__penalty=l1, log_r__solver=newton-cg.\n",
      "[CV 1/1; 1/42] END log_r__C=0.001, log_r__penalty=l1, log_r__solver=newton-cg;, score=nan total time=   0.9s\n",
      "[CV 1/1; 2/42] START log_r__C=0.001, log_r__penalty=l1, log_r__solver=lbfgs.....\n",
      "[CV 1/1; 2/42] END log_r__C=0.001, log_r__penalty=l1, log_r__solver=lbfgs;, score=nan total time=   1.0s\n",
      "[CV 1/1; 3/42] START log_r__C=0.001, log_r__penalty=l1, log_r__solver=liblinear.\n",
      "[CV 1/1; 3/42] END log_r__C=0.001, log_r__penalty=l1, log_r__solver=liblinear;, score=nan total time=   8.3s\n",
      "[CV 1/1; 4/42] START log_r__C=0.001, log_r__penalty=l2, log_r__solver=newton-cg.\n",
      "[CV 1/1; 4/42] END log_r__C=0.001, log_r__penalty=l2, log_r__solver=newton-cg;, score=nan total time= 1.3min\n",
      "[CV 1/1; 5/42] START log_r__C=0.001, log_r__penalty=l2, log_r__solver=lbfgs.....\n",
      "[CV 1/1; 5/42] END log_r__C=0.001, log_r__penalty=l2, log_r__solver=lbfgs;, score=nan total time=   3.9s\n",
      "[CV 1/1; 6/42] START log_r__C=0.001, log_r__penalty=l2, log_r__solver=liblinear.\n",
      "[CV 1/1; 6/42] END log_r__C=0.001, log_r__penalty=l2, log_r__solver=liblinear;, score=nan total time=  18.8s\n",
      "[CV 1/1; 7/42] START log_r__C=0.01, log_r__penalty=l1, log_r__solver=newton-cg..\n",
      "[CV 1/1; 7/42] END log_r__C=0.01, log_r__penalty=l1, log_r__solver=newton-cg;, score=nan total time=   1.0s\n",
      "[CV 1/1; 8/42] START log_r__C=0.01, log_r__penalty=l1, log_r__solver=lbfgs......\n",
      "[CV 1/1; 8/42] END log_r__C=0.01, log_r__penalty=l1, log_r__solver=lbfgs;, score=nan total time=   0.9s\n",
      "[CV 1/1; 9/42] START log_r__C=0.01, log_r__penalty=l1, log_r__solver=liblinear..\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "#Import tqdm to visualize algorithm run\n",
    "from tqdm.notebook import tqdm,tnrange\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, Normalizer, PowerTransformer\n",
    "\n",
    "X_train_val = pd.concat([X_train, X_val])\n",
    "# Create a list where train data indices are -1 and validation data indices are 0\n",
    "split_index = [-1 if x in X_train.index else 0 for x in X.index]\n",
    "\n",
    "# Use the list to create PredefinedSplit\n",
    "pds = PredefinedSplit(test_fold = split_index)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "parameters = {\n",
    "    'log_r__penalty' : ['l1','l2'], \n",
    "    'log_r__C'       : np.logspace(-3,3,7),\n",
    "    'log_r__solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "pipe_lr = Pipeline([('scaler', StandardScaler()), \n",
    "                    ('log_r', LogisticRegression(max_iter = 2000))])\n",
    "clf = GridSearchCV(pipe_lr, \n",
    "                   param_grid = parameters,\n",
    "                   scoring = 'roc_auc', \n",
    "                   cv = pds,\n",
    "                  verbose=10)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"ROC AUC :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092ac4a",
   "metadata": {},
   "source": [
    "### 7.2 Categorical variable encoding\n",
    "\n",
    "We had a high number of categorical variables, their encoding can significantly change our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bcc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tqdm to visualize algorithm run\n",
    "from tqdm.notebook import tqdm,tnrange\n",
    "\n",
    "#K fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "#Creating K-fold validation leaves\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "#Initializing our scores array\n",
    "scores = []\n",
    "df = df.copy()\n",
    "#Defining our encoders:\n",
    "encoders = ['mixed', 'ordinal', 'woe', 'ohe']\n",
    "\n",
    "for enc in tqdm(encoders, desc='encoder'):\n",
    "    for train_index, test_index in tqdm(kf.split(df),desc='K',total=5):\n",
    "        train = df.loc[df.index.isin(train_index)]\n",
    "        test  = df.loc[df.index.isin(test_index)]\n",
    "        \n",
    "        y_train = train[\"TARGET\"]\n",
    "        y_test = test[\"TARGET\"]\n",
    "        X_train = train.drop(columns={\"TARGET\"})\n",
    "        X_test = test.drop(columns={\"TARGET\"})\n",
    "        #Performing data imputation\n",
    "        numeric_data_imputation(X_train)\n",
    "        numeric_data_imputation(X_test)\n",
    "        \n",
    "        #Encoding variables\n",
    "        X_test = encode_cat_vars(X_test, X_train, y_train, max_categ=10, full_encode=enc)\n",
    "        X_train = encode_cat_vars(X_train, X_train, y_train, max_categ=10, full_encode=enc)\n",
    "        X_train, X_test = X_train.align(X_test, join='left', axis=1)\n",
    "\n",
    "        #Oversampling\n",
    "        X_train, y_train, X_train_init, y_train_init = over_sample_train(X_train, y_train)\n",
    "\n",
    "        #Feature selection\n",
    "        X_train, X_test = perform_variance_selection(X_train, X_test)\n",
    "        \n",
    "        roc_train, roc_test = logr_classifier(X_train, X_test)\n",
    "        print(roc_train, roc_test)\n",
    "        \n",
    "        scores.append({'Encoder': enc, 'ROC AUC train': roc_train, 'ROC_AUC_TEST': roc_test })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting our scores array into a Dataframe    \n",
    "scores = pd.DataFrame(scores)\n",
    "\n",
    "#Selecting average ROC AUC Score and accuracy by model\n",
    "scores = scores.groupby(\"Encoder\").mean().reset_index()\n",
    "\n",
    "sns.barplot(data = scores, x=\"Encoder\", y=\"ROC_AUC_TEST\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37921be7",
   "metadata": {},
   "source": [
    "**The Weight of Evidence (WoE)** encoder is the **most performant** for our Logistic Regression Algorithm.\n",
    "\n",
    "Now let's try to tune our Feature Selection process.\n",
    "\n",
    "### 7.2 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b4318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tqdm to visualize algorithm run\n",
    "from tqdm.notebook import tqdm,tnrange\n",
    "\n",
    "#K fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "#Initializing our scores array\n",
    "scores = []\n",
    "df = df.copy()\n",
    "#Defining our encoders:\n",
    "selectors = ['mixed', 'variance', 'correlation', 'kbest']\n",
    "\n",
    "for sel in tqdm(selectors, desc='Selector'):\n",
    "    for train_index, test_index in tqdm(kf.split(df),desc='K',total=3):\n",
    "        train = df.loc[df.index.isin(train_index)]\n",
    "        test  = df.loc[df.index.isin(test_index)]\n",
    "        \n",
    "        y_train = train[\"TARGET\"]\n",
    "        y_test = test[\"TARGET\"]\n",
    "        X_train = train.drop(columns={\"TARGET\"})\n",
    "        X_test = test.drop(columns={\"TARGET\"})\n",
    "        #Performing data imputation\n",
    "        numeric_data_imputation(X_train)\n",
    "        numeric_data_imputation(X_test)\n",
    "        \n",
    "        #Encoding variables\n",
    "        X_test = encode_cat_vars(X_test, X_train, y_train, max_categ=10, full_encode='woe')\n",
    "        X_train = encode_cat_vars(X_train, X_train, y_train, max_categ=10, full_encode='woe')\n",
    "        X_train, X_test = X_train.align(X_test, join='left', axis=1)\n",
    "\n",
    "        #Oversampling\n",
    "        X_train, y_train, X_train_init, y_train_init = over_sample_train(X_train, y_train)\n",
    "\n",
    "        #Feature selection\n",
    "        X_train, X_test = select_features(X_train, X_test, y_train, unique_select=sel)\n",
    "        \n",
    "        roc_train, roc_test = logr_classifier(X_train, X_test)\n",
    "        print(roc_train, roc_test)\n",
    "        \n",
    "        scores.append({'Selector': sel, 'ROC_AUC_train': roc_train, 'ROC_AUC_TEST': roc_test })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting our scores array into a Dataframe    \n",
    "scores = pd.DataFrame(scores)\n",
    "\n",
    "#Selecting average ROC AUC Score and accuracy by selector\n",
    "scores = scores.groupby(\"Selector\").mean().reset_index().sort_values(by=\"ROC_AUC_TEST\", ascending=False)\n",
    "\n",
    "sns.barplot(data = scores, x=\"Selector\", y=\"ROC_AUC_TEST\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0922a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tqdm to visualize algorithm run\n",
    "from tqdm.notebook import tqdm,tnrange\n",
    "\n",
    "#K fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True)\n",
    "\n",
    "#Initializing our scores array\n",
    "scores = []\n",
    "df = df.copy()\n",
    "#Defining our encoders:\n",
    "selectors = [['correlation', np.arange(0.7,1,0.01)],['kbest', np.arange(1,51,1)]]\n",
    "\n",
    "for sel in tqdm(selectors, desc='Selector'):\n",
    "    for param in tqdm(sel[1], desc='Hyperparameter'):\n",
    "        for train_index, test_index in tqdm(kf.split(df),desc='K',total=2):\n",
    "            train = df.loc[df.index.isin(train_index)]\n",
    "            test  = df.loc[df.index.isin(test_index)]\n",
    "\n",
    "            y_train = train[\"TARGET\"]\n",
    "            y_test = test[\"TARGET\"]\n",
    "            X_train = train.drop(columns={\"TARGET\"})\n",
    "            X_test = test.drop(columns={\"TARGET\"})\n",
    "            #Performing data imputation\n",
    "            numeric_data_imputation(X_train)\n",
    "            numeric_data_imputation(X_test)\n",
    "\n",
    "            #Encoding variables\n",
    "            X_test = encode_cat_vars(X_test, X_train, y_train, max_categ=10, full_encode='woe')\n",
    "            X_train = encode_cat_vars(X_train, X_train, y_train, max_categ=10, full_encode='woe')\n",
    "            X_train, X_test = X_train.align(X_test, join='left', axis=1)\n",
    "\n",
    "            #Oversampling\n",
    "            X_train, y_train, X_train_init, y_train_init = over_sample_train(X_train, y_train)\n",
    "\n",
    "            #Feature selection\n",
    "            X_train, X_test = select_features(X_train, X_test, y_train, unique_select=sel[0], k=param, corr_threshold=param)\n",
    "\n",
    "            roc_train, roc_test = logr_classifier(X_train, X_test)\n",
    "            print(roc_train, roc_test)\n",
    "\n",
    "            scores.append({'Selector': sel[0], 'Hyperparameter': param,\n",
    "                           'ROC AUC train': roc_train, 'ROC AUC TEST': roc_test })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcdcd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting our scores array into a Dataframe    \n",
    "scores = pd.DataFrame(scores)\n",
    "\n",
    "#Selecting average ROC AUC Score and accuracy by selector\n",
    "scores = scores.groupby([\"Selector\",\"Hyperparameter\"]).mean().reset_index().sort_values(by=\"ROC AUC TEST\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce14085",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sel in scores.Selector.unique():\n",
    "    subset = scores[scores.Selector == sel]\n",
    "    sns.lineplot(data=subset, x='Hyperparameter', y=\"ROC AUC TEST\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a380ae",
   "metadata": {},
   "source": [
    "### 6.2 Support Vector Classification (Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ceadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipe_lsvc = Pipeline([('scaler', StandardScaler()), ('svc_l', LinearSVC())])\n",
    "\n",
    "pipe_lsvc.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = pipe_lsvc.predict(X_train)\n",
    "test_predictions = pipe_lsvc.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression results\")\n",
    "print(\"TRAIN:\")\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"----------------------\")\n",
    "print(\"TEST:\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31155b24",
   "metadata": {},
   "source": [
    "### 6.3 KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d1432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe_knc = Pipeline([('scaler', StandardScaler()), ('knc', KNeighborsClassifier())])\n",
    "\n",
    "pipe_knc.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = pipe_knc.predict(X_train)\n",
    "test_predictions = pipe_knc.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression results\")\n",
    "print(\"TRAIN:\")\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"----------------------\")\n",
    "print(\"TEST:\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:project_4]",
   "language": "python",
   "name": "conda-env-project_4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "569.6px",
    "left": "83px",
    "top": "110.325px",
    "width": "304.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
